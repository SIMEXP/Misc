{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This gets connectomes and returns them to you"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import sys\n",
    "import glob\n",
    "import time\n",
    "import gzip\n",
    "import cPickle\n",
    "import numpy as np\n",
    "import nibabel as nib\n",
    "import subprocess as sp\n",
    "from scipy import io as si"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# This is a helper function\n",
    "def run_comm(command, verbose=False, wget=False):\n",
    "    p = sp.Popen(command, stdout = sp.PIPE, \n",
    "                 stderr = sp.STDOUT, shell = True)\n",
    "    message = ''\n",
    "    # Talk a little bit about what's going on and give a progress report\n",
    "    while verbose:\n",
    "        line = p.stdout.readline()\n",
    "        message = line\n",
    "        if not line: \n",
    "            print('stop!')\n",
    "            break\n",
    "        else:\n",
    "            if wget:\n",
    "                size = re.search('[0-9]+[A-Z]',line)\n",
    "                prog = re.search('[0-9]+%.*',line)\n",
    "                if prog and size:\n",
    "                    pg = prog.group()\n",
    "                    sg = size.group()\n",
    "                    message = sg + ' ' + pg\n",
    "        sys.stdout.write('\\r {}'.format(message))\n",
    "        sys.stdout.flush()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Define the work path. This is where all the files will end up\n",
    "work_path = '/data1/test/connectome'\n",
    "mask_dir = os.path.join(work_path, 'mask')\n",
    "data_dir = os.path.join(work_path, 'data')   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# See if we need to download anything\n",
    "This can take quite a long time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The mask folder is already there, I assume that all the files are inside\n",
      "The data folder is already there, I assume that all the files are inside\n"
     ]
    }
   ],
   "source": [
    "if not os.path.isdir(mask_dir):\n",
    "    os.makedirs(mask_dir)\n",
    "    print('I am downloading the template files form figshare')\n",
    "    comm1 = 'wget http://files.figshare.com/1861819/template_cambridge_basc_multiscale_nii_sym.zip -P {}'.format(mask_dir)\n",
    "    run_comm(comm1)\n",
    "    comm2 = 'unzip {} -d {}'.format(os.path.join(mask_dir,'template_cambridge_basc_multiscale_nii_sym.zip'), mask_dir)\n",
    "    run_comm(comm2)\n",
    "    comm3 = 'mv {} {}'.format(os.path.join(mask_dir, 'template_cambridge_basc_multiscale_nii_sym', '*'), mask_dir)\n",
    "    run_comm(comm3)\n",
    "    comm4 = 'rm -rf {}'.format(os.path.join(mask_dir, 'template_cambridge_basc_multiscale_nii_sym'))\n",
    "    run_comm(comm4)\n",
    "    comm5 = 'rm {}'.format(os.path.join(mask_dir, 'template_cambridge_basc_multiscale_nii_sym.zip'))\n",
    "    run_comm(comm5)\n",
    "else:\n",
    "    print('The mask folder is already there, I assume that all the files are inside')\n",
    "    \n",
    "if not os.path.isdir(data_dir):\n",
    "    os.makedirs(data_dir)\n",
    "    print('I am downloading the data form figshare')\n",
    "    comm1 = 'wget http://downloads.figshare.com/article/public/1160600 -P {}'.format(data_dir)\n",
    "    run_comm(comm1, True, True)\n",
    "    comm2 = 'unzip {} -d {}'.format(os.path.join(data_dir, '1160600'), os.path.join(data_dir, 'tmp'))\n",
    "    run_comm(comm2, True)\n",
    "    comm3 = 'mv {}/* {} -v'.format(os.path.join(data_dir, 'out'), data_dir)\n",
    "    run_comm(comm3)\n",
    "    comm4 = 'rm -rfv {} {}'.format(os.path.join(data_dir, '1160600'), os.path.join(data_dir, 'tmp'))\n",
    "    run_comm(comm3, True)\n",
    "else:\n",
    "    print('The data folder is already there, I assume that all the files are inside')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Begin with generating the connectomes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Set up some things\n",
    "out_dir = os.path.join(work_path, 'connectomes')\n",
    "if not os.path.isdir(out_dir):\n",
    "    os.makedirs(out_dir)\n",
    "\n",
    "mask_temp = 'template_cambridge_basc_multiscale_sym_scale{:03}.nii.gz'\n",
    "data_temp = 'fmri_*_session1_run1.nii.gz'\n",
    "out_temp = 'connectomes_cobre_{}.{}'\n",
    "\n",
    "# These are the scales that the cambridge template comes in\n",
    "scales = [7,12,20,36,64,122,197,325,444]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Get all the files in the directory\n",
    "files = glob.glob(os.path.join(data_dir, data_temp))\n",
    "subs = dict()\n",
    "for f in files:\n",
    "    fname = os.path.basename(f)\n",
    "    # Get the subject name\n",
    "    sub = re.search('(?<=fmri_)[a-zA-Z0-9]+',fname).group()\n",
    "    if not sub in subs.keys():\n",
    "        subs[sub] = f\n",
    "    else:\n",
    "        message('There are 2 of {}, the second one was {}'.format(sub, f))\n",
    "        raise Exception(message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "num_subs = len(subs.keys())\n",
    "scale_dict = dict()\n",
    "for scale in scales:\n",
    "    scale_name = 'scale_{}'.format(scale)\n",
    "    mask_name = mask_temp.format(scale)\n",
    "    mask_path = os.path.join(mask_dir, mask_name)\n",
    "    m_img = nib.load(mask_path)\n",
    "    mask = m_img.get_data()\n",
    "    scale_dict[scale_name] = (mask, np.unique(mask[mask!=0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " #146 took 1.444 seconds, 100.0% done, 0.00 more seconds to go"
     ]
    }
   ],
   "source": [
    "cobre_connectomes = dict()\n",
    "num_subs = len(subs.keys())\n",
    "avg_time = np.array([])\n",
    "for s_id, sub in enumerate(subs.keys()):\n",
    "    p_c = float(s_id + 1) / num_subs * 100\n",
    "    rem = num_subs - (s_id + 1)\n",
    "\n",
    "    start = time.time()\n",
    "    s_img = nib.load(subs[sub])\n",
    "    data = s_img.get_data()\n",
    "    t_points = data.shape[3]\n",
    "\n",
    "    for scale in scales:\n",
    "        scale_name = 'scale_{}'.format(scale)\n",
    "        mask = scale_dict[scale_name][0]\n",
    "        rois = scale_dict[scale_name][1]\n",
    "        num_rois = len(rois)\n",
    "\n",
    "        data_rois = np.zeros((num_rois, t_points))\n",
    "        for ind, roi in enumerate(rois):\n",
    "            data_rois[ind,:] = np.mean(data[mask==roi,:],axis=0)\n",
    "        mat = np.corrcoef(data_rois)\n",
    "\n",
    "        if not scale_name in cobre_connectomes.keys():\n",
    "            cobre_connectomes[scale_name] = np.zeros((num_rois, num_rois, num_subs))\n",
    "        cobre_connectomes[scale_name][..., s_id] = mat\n",
    "    stop = time.time()\n",
    "    took = stop - start\n",
    "    avg_time = np.append(avg_time, took)\n",
    "    avg = np.average(avg_time)\n",
    "    rem_t = rem * avg\n",
    "    sys.stdout.write('\\r #{} took {:.3f} seconds, {:.1f}% done, {:.2f} more seconds to go'.format(s_id+1, took, p_c, rem_t))\n",
    "    sys.stdout.flush()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save the output in a big file for convenience"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Save the subjects in the dictionary as well\n",
    "cobre_connectomes['subjects'] = subs.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Save the dictionary as a .mat file\n",
    "si.savemat(os.path.join(work_path, out_temp.format('all','mat')), cobre_connectomes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Save the dictionary as a zipped pickle\n",
    "with gzip.open(os.path.join(work_path, out_temp.format('all','gz')), 'wb') as f:\n",
    "    cPickle.dump(cobre_connectomes, f, protocol=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save the output in separate files for figshare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mat_p = os.path.join(work_path, 'matlab')\n",
    "if not os.path.isdir(mat_p):\n",
    "    os.makedirs(mat_p)\n",
    "gzp_p = os.path.join(work_path, 'zippickle')\n",
    "if not os.path.isdir(gzp_p):\n",
    "    os.makedirs(gzp_p)\n",
    "npy_p = os.path.join(work_path, 'numpy')\n",
    "if not os.path.isdir(npy_p):\n",
    "    os.makedirs(npy_p)\n",
    "    \n",
    "for key in cobre_connectomes.keys():\n",
    "    tmp = cobre_connectomes[key]\n",
    "    if key == 'subjects':\n",
    "        # Write out the list of subjects as a text file\n",
    "        sub_f = os.path.join(work_path, 'subjects.txt')\n",
    "        with open(sub_f, 'wb') as f:\n",
    "            for item in tmp:\n",
    "                f.write('{}\\n'.format(item))\n",
    "        # Continue with the next key\n",
    "        continue\n",
    "    # Save the array as a .mat file\n",
    "    mat_f = os.path.join(mat_p ,out_temp.format(key,'mat'))\n",
    "    gzp_f = os.path.join(gzp_p ,out_temp.format(key,'gz'))\n",
    "    npy_f = os.path.join(npy_p ,out_temp.format(key,'npy'))\n",
    "    si.savemat(mat_f, {'{}'.format(key):tmp})\n",
    "    with gzip.open(gzp_f, 'wb') as f:\n",
    "        cPickle.dump(tmp, f, protocol=2)\n",
    "    np.save(npy_f, tmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
